# Lucene 使用记录


Lucene不是一个完整的全文索引应用，而是是一个用Java写的全文索引引擎工具包，它可以方便的嵌入到各种应用中实现针对应用的全文索引/检索功能。  

## 全文检索的实现机制


Lucene的API接口设计的比较通用，输入输出结构都很像数据库的表==>记录==>字段，所以很多传统的应用的文件、数据库等都可以比较方便的映射到Lucene的存储结构/接口中。  

总体上看：可以先把Lucene当成一个支持全文索引的数据库系统。  

索引之所以效率高，另外一个原因是它是排好序的。  

对于检索系统来说核心是一个排序问题。  


由于数据库索引不是为全文索引设计的，因此，使用like "%keyword%"时，数据库索引是不起作用的，在使用like查询时，搜索过程又变成类似于一页页翻书的遍历过程了，所以对于含有模糊查询的数据库服务来说，LIKE对性能的危害是极大的。  

所以建立一个高效检索系统的关键是建立一个类似于科技索引一样的反向索引机制，将数据源（比如多篇文章）排序顺序存储的同时，有另外一个排好序的关键词列表，用于存储关键词==>文章映射关系，利用这样的映射关系索引：\[关键词==>出现关键词的文章编号，出现次数（甚至包括位置：起始偏移量，结束偏移量），出现频率\]，检索过程就是把模糊查询变成多个可以利用索引的精确查询的逻辑组合的过程。  
从而大大提高了多关键词查询的效率，所以，全文检索问题归结到最后是一个排序问题。  


由此可以看出模糊查询相对数据库的精确查询是一个非常不确定的问题，这也是大部分数据库对全文检索支持有限的原因。  
Lucene最核心的特征是通过特殊的索引结构实现了传统数据库不擅长的全文索引机制，并提供了扩展接口，以方便针对不同应用的定制。  

全文检索和数据库应用最大的不同在于：让最相关的头100条结果满足98%以上用户的需求  


大部分的搜索（数据库）引擎都是用B树结构来维护索引，索引的更新会导致大量的IO操作，Lucene在实现中，对此稍微有所改进：不是维护一个索引文件，而是在扩展索引的时候不断创建新的索引文件，然后定期的把这些新的小索引文件合并到原先的大索引中（针对不同的更新策略，批次的大小可以调整），这样在不影响检索的效率的前提下，提高了索引的效率。  


## 切分词问题(Word Segment)

对于中文来说，全文索引首先还要解决一个语言分析的问题，对于英文来说，语句中单词之间是天然通过空格分开的，但亚洲语言的中日韩文语句中的字是一个字挨一个，所有，首先要把语句中按“词”进行索引的话，这个词如何切分出来就是一个很大的问题。  


首先，肯定不能用单个字符作(si-gram)为索引单元，否则查“上海”时，不能让含有“海上”也匹配。   


另外一个解决的办法是采用自动切分算法：将单词按照2元语法(bigram)方式切分出来，比如："北京天安门" ==> "北京 京天 天安 安门"。  

这样，在查询的时候，无论是查询"北京" 还是查询"天安门"，将查询词组按同样的规则进行切分："北京"，"天安安门"，多个关键词之间按与"and"的关系组合，同样能够正确地映射到相应的索引中。这种方式对于其他亚洲语言：韩文，日文都是通用的。  


基于自动切分的最大优点是没有词表维护成本，实现简单，缺点是索引效率低，但对于中小型应用来说，基于2元语法的切分还是够用的。基于2元切分后的索引一般大小和源文件差不多，而对于英文，索引文件一般只有原文件的30%-40%不同  


## 安装和使用


下载 [lucene][lucene-core]  
Lucene中的一些比较复杂的词法分析是用 JavaCC 生成的。  
所以如果从源代码编译或需要修改其中的QueryParser、定制自己的词法分析器，还需要安装 JavaCC。  


lucene的组成结构：对于外部应用来说索引模块(index)和检索模块(search)是主要的外部应用入口  


org.apache.Lucene.search/	搜索入口
org.apache.Lucene.index/	索引入口
org.apache.Lucene.analysis/	语言分析器
org.apache.Lucene.queryParser/	查询分析器
org.apache.Lucene.document/	存储结构
org.apache.Lucene.store/ 	底层IO/存储结构
org.apache.Lucene.util/	一些公用的数据结构












[lucene-core]: http://lucene.apache.org/core/
[chedong-lucene]: http://www.chedong.com/tech/lucene.html
